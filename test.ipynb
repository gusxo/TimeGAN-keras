{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/user/backup/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 07:43:22.076487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from timegan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(dir, filecnt=54):\n",
    "    data = [None]*10\n",
    "    t = np.zeros((10, filecnt), int)\n",
    "    for p in range(10):\n",
    "        d = [None]*filecnt\n",
    "        for i in range(filecnt):\n",
    "            d[i] = np.load(f\"{dir}/{p}/{i+1}.npy\")\n",
    "            t[p,i] = d[i].shape[0]\n",
    "        data[p] = d\n",
    "    return data, t\n",
    "\n",
    "def load_with_config(dir, config_path, load_nonvalid=False):\n",
    "    config_arr = np.array(pd.read_csv(f\"{config_path}\", header=None, skiprows=1))\n",
    "    data = [[] for i in range(10)]          #create empty 2d list : (10, unknown)\n",
    "    for config in config_arr:\n",
    "        #valid check\n",
    "        if (not config[2]) and (not load_nonvalid):\n",
    "            continue\n",
    "        data[int(config[0])] += [np.load(f\"{dir}/{int(config[0])}/{int(config[1])+1}.npy\")[int(config[3]):int(config[4]),:]]\n",
    "    \n",
    "    return data, config_arr\n",
    "\n",
    "def match_length(d, t:int):\n",
    "    \"\"\"\n",
    "    return\n",
    "        x : (N, times(t), 2) shape numpy array,\n",
    "        y : (N)\n",
    "    \"\"\"\n",
    "    N = sum([len(d[i]) for i in range(len(d))])\n",
    "    x = np.zeros((N, t, 2), np.float64)\n",
    "    y = np.zeros((N), np.float64)\n",
    "    target_timepoints = np.linspace(0, 1, t)\n",
    "    start_at = 0\n",
    "    for r in range(len(d)):\n",
    "        for c in range(len(d[r])):\n",
    "            origin_timepoints = np.linspace(0, 1, d[r][c].shape[0])\n",
    "            x[start_at + c, :, 0] = np.interp(target_timepoints, origin_timepoints, d[r][c][:,0])\n",
    "            x[start_at + c, :, 1] = np.interp(target_timepoints, origin_timepoints, d[r][c][:,1])\n",
    "        y[start_at:start_at + len(d[r])] = r\n",
    "        start_at += len(d[r])\n",
    "    return x, y \n",
    "\n",
    "def apply_normalize(d):\n",
    "    for r in range(len(d)):\n",
    "        for c in range(len(d[r])):\n",
    "            channels = d[r][c].shape[1]\n",
    "            min_vals = np.min(d[r][c][:, :], axis=0)\n",
    "            max_vals = np.max(d[r][c][:, :], axis=0)\n",
    "            min_max_diff = np.array([max_vals[j] - min_vals[j] for j in range(channels)])\n",
    "            factor = min_max_diff / np.max(min_max_diff)\n",
    "            for ch in range(channels):\n",
    "                d[r][c][:, ch] = ((d[r][c][:, ch] - min_vals[ch])/min_max_diff[ch])*factor[ch]\n",
    "    \n",
    "def plot_data(d):\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.subplot(2,1,1)\n",
    "    gca = plt.gca()\n",
    "    gca.plot(d[:,0])\n",
    "    plt.subplot(2,1,2)\n",
    "    gca = plt.gca()\n",
    "    gca.plot(d[:,1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_data2(d, save=None, cmap_name=\"gist_rainbow\", xlim1=None, ylim1=None, xlim2=None, ylim2=None, xlim3=None, ylim3=None):\n",
    "    fig, axes = plt.subplot_mosaic(\"abbbb;acccc\", figsize=(20,4))\n",
    "    utils.draw_gradation(d[:,0], d[:,1], axes[\"a\"],cmap_name=cmap_name, xlim=xlim1, ylim=ylim1)\n",
    "    utils.draw_gradation(np.arange(d.shape[0]), d[:,0], axes[\"b\"],cmap_name=cmap_name, xlim=xlim2, ylim=ylim2)\n",
    "    utils.draw_gradation(np.arange(d.shape[0]), d[:,1], axes[\"c\"],cmap_name=cmap_name, xlim=xlim3, ylim=ylim3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save)\n",
    "        plt.close()\n",
    "\n",
    "def plot_data3(origin, syn, save=None, cmap_name=\"gist_rainbow\", hightitle=\"Original\", lowtitle=\"Synthetic\"):\n",
    "    fig, axes = plt.subplot_mosaic(\"abbbb;acccc;deeee;dffff\", figsize=(20,8))\n",
    "    utils.draw_gradation(origin[:,0], origin[:,1], axes[\"a\"],cmap_name=cmap_name, xlim=[0,1], ylim=[0,1])\n",
    "    utils.draw_gradation(np.arange(origin.shape[0]), origin[:,0], axes[\"b\"],cmap_name=cmap_name, ylim=[0,1])\n",
    "    utils.draw_gradation(np.arange(origin.shape[0]), origin[:,1], axes[\"c\"],cmap_name=cmap_name, ylim=[0,1])\n",
    "    utils.draw_gradation(syn[:,0], syn[:,1], axes[\"d\"], cmap_name=cmap_name, xlim=[0,1], ylim=[0,1])\n",
    "    utils.draw_gradation(np.arange(syn.shape[0]), syn[:,0], axes[\"e\"],cmap_name=cmap_name, ylim=[0,1])\n",
    "    utils.draw_gradation(np.arange(syn.shape[0]), syn[:,1], axes[\"f\"],cmap_name=cmap_name, ylim=[0,1])\n",
    "    axes[\"a\"].set_title(hightitle)\n",
    "    axes[\"d\"].set_title(lowtitle)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save)\n",
    "        plt.close()\n",
    "\n",
    "def plot_data4(datas, save=None, titles=None, cmap_name=\"winter_r\"):\n",
    "    plotlen = len(datas)\n",
    "    mosaic_input = [None] * (plotlen << 1)\n",
    "    for i in range(plotlen):\n",
    "        j = i << 1\n",
    "        mosaic_input[j] = [f\"{i}a\"] + [f\"{i}x\"] * 4\n",
    "        mosaic_input[j+1] = [f\"{i}a\"] + [f\"{i}y\"] * 4\n",
    "    fig, axes = plt.subplot_mosaic(mosaic_input, figsize=(20, 4 * plotlen))\n",
    "    for i in range(plotlen):\n",
    "        if titles is not None:\n",
    "            axes[f\"{i}a\"].set_title(titles[i])\n",
    "        utils.draw_gradation(datas[i][:,0], datas[i][:,1], axes[f\"{i}a\"], cmap_name=cmap_name, xlim=[0,1], ylim=[0,1])\n",
    "        x_indexes = np.arange(datas[i].shape[0])\n",
    "        utils.draw_gradation(x_indexes, datas[i][:,0], axes[f\"{i}x\"], cmap_name=cmap_name, ylim=[0,1])\n",
    "        utils.draw_gradation(x_indexes, datas[i][:,1], axes[f\"{i}y\"], cmap_name=cmap_name, ylim=[0,1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, config = load_with_config(\"/home/user/workspace/research/eye-writing/self_data/\", \"/home/user/workspace/research/eye-writing/load_data_config.csv\", load_nonvalid=False)\n",
    "apply_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 200, 2)\n",
      "(505,)\n",
      "(51, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "x, y = match_length(data, 200)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "pattern = 0\n",
    "x = x[y==pattern]\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 07:40:31.613251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:31.626874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:31.627133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:31.628195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 07:40:31.629670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:31.629868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:31.630091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:32.760247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:32.760984: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:32.760997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-22 07:40:32.761234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-22 07:40:32.761559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9368 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]2023-02-22 07:40:36.774208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-02-22 07:40:37.841566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-22 07:40:38.497185: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x6bff4010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-22 07:40:38.497247: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2023-02-22 07:40:38.528720: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-22 07:40:38.772999: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f610c10e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f610c10e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [05:03<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1067/2000 [27:19<23:00,  1.48s/it]"
     ]
    }
   ],
   "source": [
    "rnn_units = 24\n",
    "rnn_layers = 3\n",
    "batch_size = 32\n",
    "lr = 0.0005\n",
    "epoch = 2000\n",
    "save_name = f\"/home/user/backup/synckpt_test_{pattern}/\"\n",
    "import os\n",
    "\n",
    "z = np.random.uniform(size=(batch_size, x.shape[1], x.shape[2]))\n",
    "\n",
    "if os.path.isdir(save_name):\n",
    "    print(f\"체크포인트 있음, 불러옴.\")\n",
    "    syn_gen = generator_load(save_name, x.shape[1], x.shape[2], rnn_units, rnn_layers)\n",
    "else:\n",
    "    timegan_tuple = timegan_init(x.shape[1], x.shape[2], rnn_units, rnn_layers)\n",
    "    timegan_tuple = timegan_train(x, timegan_tuple, epochs=epoch, batch_size=batch_size, learning_rate=lr)\n",
    "    syn_gen = timegan_export_generator(timegan_tuple)\n",
    "    # generator_save(syn_gen, save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synth_data = generator_gen(syn_gen, batch_size)\n",
    "# synth_data.shape\n",
    "e, g, s, r ,d = timegan_tuple\n",
    "# synth_data = e(x)\n",
    "# synth_data = r(synth_data)\n",
    "# synth_data = g(z)\n",
    "# synth_data = s(synth_data)\n",
    "\n",
    "e_l = e(x)\n",
    "e_l_r = r(e_l)\n",
    "g_l = g(z)\n",
    "g_l_r = r(g_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"/home/user/output\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "files = glob.glob(f'{save_dir}/*.png')\n",
    "for f in files:\n",
    "    try:\n",
    "        os.remove(f)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "\n",
    "# for i in range(len(synth_data)):\n",
    "#     plot_data3(x[i], synth_data[i], f\"{save_dir}/{i}.png\", \"winter_r\")\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plot_data4(datas=[x[i], e_l[i], e_l_r[i], g_l[i], g_l_r[i]],\n",
    "     save=f\"{save_dir}/{i}.png\", \n",
    "     titles=[\"x\", \"x -> latent code\", \"reconstructed data\", \"z -> latent code\", \"z -> reconstrcution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
